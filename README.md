# Churn Modeling

A machine learning project to predict customer churn using various classification algorithms and exploratory data analysis.

## Table of Contents

- [Overview](#overview)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Dependencies](#dependencies)
- [Usage](#usage)
- [Data](#data)
- [Features](#features)
- [Models](#models)
- [Contributing](#contributing)
- [License](#license)

## Overview

This project focuses on building predictive models to identify customers who are likely to churn. It includes data ingestion from Kaggle, exploratory data analysis (EDA), data preprocessing, and machine learning model development using multiple algorithms.

**Author:** Kirti Verma  
**Email:** kv.edu14@gmail.com

## Project Structure

```
Churn_Modeling/
├── data/
│   └── raw/
│       └── Churn_Modelling.csv
├── notebook/
│   └── EDA.ipynb
├── src/
│   ├── __init__.py
│   ├── logger.py
│   ├── exception.py
│   └── components/
│       ├── __init__.py
│       └── data_ingestion.py
├── Logs/
├── requirements.txt
├── setup.py
├── README.md
└── LICENSE
```

### Directory Descriptions

- **data/raw/**: Contains raw datasets downloaded from Kaggle (Churn_Modelling.csv)
- **notebook/**: Jupyter notebooks for exploratory data analysis and model development
  - `EDA.ipynb`: Exploratory data analysis notebook
- **src/**: Source code for the project
  - `logger.py`: Logging configuration for tracking execution
  - `exception.py`: Custom exception handling with detailed error tracking
  - `components/data_ingestion.py`: Module for downloading and ingesting data from Kaggle
- **Logs/**: Directory containing execution logs with timestamps
- **CHURN_MODELING.egg-info/**: Package information (auto-generated by setuptools)

## Installation

### Prerequisites

- Python 3.7 or higher
- pip (Python package manager)
- Virtual environment (recommended)

### Setup Instructions

1. **Clone the repository:**
   ```bash
   git clone https://github.com/kirti2k23/Churn_Modeling.git
   cd Churn_Modeling
   ```

2. **Create and activate a virtual environment:**
   ```bash
   python -m venv env
   # On Windows
   env\Scripts\activate
   # On macOS/Linux
   source env/bin/activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Install the package in development mode:**
   ```bash
   pip install -e .
   ```

## Dependencies

The project uses the following Python libraries:

| Package | Purpose |
|---------|---------|
| **pandas** | Data manipulation and analysis |
| **numpy** | Numerical computing |
| **matplotlib** | Data visualization |
| **seaborn** | Statistical data visualization |
| **scikit-learn** | Machine learning algorithms and tools |
| **xgboost** | Gradient boosting framework |
| **catboost** | Categorical boosting framework |
| **kaggle** | Kaggle API for dataset download |
| **jupyter** | Interactive notebook environment |

See `requirements.txt` for complete version specifications.

## Usage

### Data Ingestion

The `DataIngestion` class in `src/components/data_ingestion.py` handles downloading the Churn dataset from Kaggle:

```python
from src.components.data_ingestion import DataIngestion

# Initialize and download data
data_ingestion = DataIngestion()
# Downloads data to data/raw/ folder
```

### Logging

The project includes comprehensive logging functionality:

```python
from src.logger import logging

logging.info("Your log message here")
```

Logs are saved to the `Logs/` directory with timestamps in the filename.

### Exception Handling

Custom exceptions provide detailed error information with file and line numbers:

```python
from src.exception import MyCustomException

try:
    # Your code here
    pass
except Exception as e:
    raise MyCustomException(e)
```

### Exploratory Data Analysis

Open and run the EDA notebook:

```bash
jupyter notebook notebook/EDA.ipynb
```

## Data

### Dataset

- **Source:** Kaggle (Churn_Modelling dataset)
- **Location:** `data/raw/Churn_Modelling.csv`
- **Downloaded via:** Kaggle API

To download the dataset, you'll need:
1. A Kaggle account
2. Kaggle API credentials in `~/.kaggle/kaggle.json`

## Features

- ✅ Automated data ingestion from Kaggle
- ✅ Comprehensive logging with timestamps
- ✅ Custom exception handling with detailed traceback
- ✅ Exploratory data analysis in Jupyter notebooks
- ✅ Multiple machine learning algorithms:
  - scikit-learn classifiers
  - XGBoost
  - CatBoost
- ✅ Modular project structure for scalability

## Models

The project implements various classification models for churn prediction:

- **Scikit-learn:** Logistic Regression, Random Forest, SVM, Decision Trees
- **XGBoost:** Gradient boosting implementation
- **CatBoost:** Categorical feature-focused boosting

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the LICENSE file in the repository.

---

For questions or issues, please contact the author at kv.edu14@gmail.com
